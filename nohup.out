mkdir -p data/DBPedia
Please Download UMLS2021AA full from https://www.nlm.nih.gov/research/umls/licensedcontent/umlsknowledgesources.html
# git clone https://github.com/chanzuckerberg/MedMentions
# mkdir -p data/raw/pubmed
# wget https://databus.dbpedia.org/ontologies/dbpedia.org/ontology--DEV/2021.07.09-070001/ontology--DEV_type=parsed_sorted.nt # DBPedia Ontlogy
# for f in `find MedMentions/ | grep gz`; do gunzip $f; done
# for f in `seq -w 1062`; do wget https://ftp.ncbi.nlm.nih.gov/pubmed/baseline/pubmed21n$f.xml.gz ; gunzip pubmed21n$f.xml.gz & done
You need UMLS Account, so please acces by web browser and mv the file into data/2021AA-full
# # Wikipedia in DBPedia
# unzip data/2021AA-full/mmsys.zip
# mv MedMentions data/gold/MedMentions
# mv pubmed21n*.xml data/raw/pubmed
# wget https://databus.dbpedia.org/dbpedia/mappings/instance-types/2021.06.01/instance-types_lang=en_specific.ttl.bz2 # Wikipedia Articles Types
# cp data/gold/MedMentions/full/data/corpus_pubtator_pmids_trng.txt data/gold/MedMentions/st21pv/data/
# for f in `ls data/raw/pubmed/pubmed21n*.xml`; do poetry run python -m cli.preprocess.load_pubmed_txt $f & done
Plaese refer to README.md
# wget https://databus.dbpedia.org/dbpedia/generic/labels/2021.06.01/labels_lang=en.ttl.bz2 # Wikipedia Article Label
# cp data/gold/MedMentions/full/data/corpus_pubtator_pmids_dev.txt data/gold/MedMentions/st21pv/data/
# wget https://databus.dbpedia.org/dbpedia/mappings/mappingbased-literals/2021.06.01/mappingbased-literals_lang=en.ttl.bz2 ## Literals extracted with mappings 
# cp data/gold/MedMentions/full/data/corpus_pubtator_pmids_test.txt data/gold/MedMentions/st21pv/data/
# wget https://databus.dbpedia.org/dbpedia/generic/infobox-properties/2021.06.01/infobox-properties_lang=en.ttl.bz2 ## Extracted facts from Wikipedia Infoboxes 
# wget https://databus.dbpedia.org/dbpedia/generic/redirects/2021.06.01/redirects_lang=en.ttl.bz2	## redirects dataset
# # Wikidata in DBPedia
# wget https://databus.dbpedia.org/dbpedia/wikidata/instance-types/2021.06.01/instance-types_specific.ttl.bz2 # Type of Wikidata Instance
# wget https://databus.dbpedia.org/dbpedia/wikidata/labels/2021.03.01/labels.ttl.bz2 # Wikidata Labels
# wget https://databus.dbpedia.org/dbpedia/wikidata/ontology-subclassof/2021.02.01/ontology-subclassof.ttl.bz2 # Wikidata SubClassOf
# wget https://databus.dbpedia.org/dbpedia/wikidata/alias/2021.02.01/alias.ttl.bz2 # Wikidata Alias
# bunzip2 *.bz2
# mv *.ttl data/DBPedia
# mv *.nt data/DBPedia
make dict files data/dict/T005
poetry run python -m cli.preprocess.load_terms --category T005 --output data/dict/T005
make dict files data/dict/T022
make dict files data/dict/T058
make dict files data/dict/T062
make dict files data/dict/T038
make dict files data/dict/T017
make dict files data/dict/T031
make dict files data/dict/T037
make dict files data/dict/T033
make dict files data/dict/T007
make dict files data/dict/T082
make dict files data/dict/T074
poetry run python -m cli.preprocess.load_terms --category T062 --output data/dict/T062
poetry run python -m cli.preprocess.load_terms --category T038 --output data/dict/T038
poetry run python -m cli.preprocess.load_terms --category T007 --output data/dict/T007
poetry run python -m cli.preprocess.load_terms --category T017 --output data/dict/T017
poetry run python -m cli.preprocess.load_terms --category T022 --output data/dict/T022
poetry run python -m cli.preprocess.load_terms --category T031 --output data/dict/T031
poetry run python -m cli.preprocess.load_terms --category T033 --output data/dict/T033
poetry run python -m cli.preprocess.load_terms --category T037 --output data/dict/T037
poetry run python -m cli.preprocess.load_terms --category T058 --output data/dict/T058
poetry run python -m cli.preprocess.load_terms --category T074 --output data/dict/T074
poetry run python -m cli.preprocess.load_terms --category T082 --output data/dict/T082
make dict files data/dict/T092
poetry run python -m cli.preprocess.load_terms --category T092 --output data/dict/T092
make dict files data/dict/T103
make dict files data/dict/T091
make dict files data/dict/T097
make dict files data/dict/T098
poetry run python -m cli.preprocess.load_terms --category T091 --output data/dict/T091
make dict files data/dict/T168
make dict files data/dict/T170
make dict files data/dict/T201
make dict files data/dict/T204
make dict files data/dict/T004
make dict files data/dict/T002
make dict files data/dict/T194
poetry run python -m cli.preprocess.load_terms --category T097 --output data/dict/T097
poetry run python -m cli.preprocess.load_terms --category T098 --output data/dict/T098
poetry run python -m cli.preprocess.load_terms --category T103 --output data/dict/T103
poetry run python -m cli.preprocess.load_terms --category T168 --output data/dict/T168
poetry run python -m cli.preprocess.load_terms --category T170 --output data/dict/T170
poetry run python -m cli.preprocess.load_terms --category T201 --output data/dict/T201
poetry run python -m cli.preprocess.load_terms --category T204 --output data/dict/T204
poetry run python -m cli.preprocess.load_terms --category T002 --output data/dict/T002
poetry run python -m cli.preprocess.load_terms --category T004 --output data/dict/T004
poetry run python -m cli.preprocess.load_terms --category T194 --output data/dict/T194
make dict files data/dict/T200
make dict files data/dict/T075
poetry run python -m cli.preprocess.load_terms --category T075 --output data/dict/T075
poetry run python -m cli.preprocess.load_terms --category T200 --output data/dict/T200
make dict files data/dict/T081
make dict files data/dict/T079
make dict files data/dict/T080
make dict files data/dict/T102
make dict files data/dict/T171
make dict files data/dict/T099
make dict files data/dict/T054
make dict files data/dict/T100
make dict files data/dict/T101
make dict files data/dict/T055
poetry run python -m cli.preprocess.load_terms --category T081 --output data/dict/T081
poetry run python -m cli.preprocess.load_terms --category T080 --output data/dict/T080
poetry run python -m cli.preprocess.load_terms --category T079 --output data/dict/T079
poetry run python -m cli.preprocess.load_terms --category T171 --output data/dict/T171
poetry run python -m cli.preprocess.load_terms --category T102 --output data/dict/T102
poetry run python -m cli.preprocess.load_terms --category T099 --output data/dict/T099
poetry run python -m cli.preprocess.load_terms --category T100 --output data/dict/T100
poetry run python -m cli.preprocess.load_terms --category T101 --output data/dict/T101
poetry run python -m cli.preprocess.load_terms --category T054 --output data/dict/T054
poetry run python -m cli.preprocess.load_terms --category T055 --output data/dict/T055
make dict files data/dict/T056
poetry run python -m cli.preprocess.load_terms --category T056 --output data/dict/T056
make dict files data/dict/T064
poetry run python -m cli.preprocess.load_terms --category T064 --output data/dict/T064
make dict files data/dict/T065
poetry run python -m cli.preprocess.load_terms --category T065 --output data/dict/T065
make pseudo ner data from data/dict/T005 data/dict/T007 data/dict/T017 data/dict/T022 data/dict/T031 data/dict/T033 data/dict/T037 data/dict/T038 data/dict/T058 data/dict/T062 data/dict/T074 data/dict/T082 data/dict/T091 data/dict/T092 data/dict/T097 data/dict/T098 data/dict/T103 data/dict/T168 data/dict/T170 data/dict/T201 data/dict/T204 data/dict/T002 data/dict/T004 data/dict/T194 data/dict/T075 data/dict/T200 data/dict/T081 data/dict/T080 data/dict/T079 data/dict/T171 data/dict/T102 data/dict/T099 data/dict/T100 data/dict/T101 data/dict/T054 data/dict/T055 data/dict/T056 data/dict/T064 data/dict/T065 data/dict/T066 data/dict/T068
focused categories: T005 T007 T017 T022 T031 T033 T037 T038 T058 T062 T074 T082 T091 T092 T097 T098 T103 T168 T170 T201 T204
duplicated categories: GeneLocation Species Disease Work SportsSeason Device Media SportCompetitionResult EthnicGroup Protocol Award Demographics MeanOfTransportation FileSystem Medicine Area Flag UnitOfWork MedicalSpecialty GrossDomesticProduct Biomolecule Identifier Blazon PersonFunction List TimePeriod Event Relationship Altitude TopicalConcept Spreadsheet Currency Cipher Browser Tank Food Depth Population Statistic StarCluster Language GrossDomesticProductPerCapita ChemicalSubstance ElectionDiagram Diploma Place Algorithm ChartsPlacements Unknown Activity PublicService Agent Name AnatomicalStructure Colour
output dir: data/pseudo/8e1dde9d958882da575aad4ef12ad72bacde6032
poetry run python -m cli.preprocess.load_pseudo_ner \
	+raw_corpus=data/raw/adc83b19e793491b1c6ea0fd8b46cd9f32e592fc \
	++ner_model.typer.term2cat.focus_cats=T005_T007_T017_T022_T031_T033_T037_T038_T058_T062_T074_T082_T091_T092_T097_T098_T103_T168_T170_T201_T204 \
	++ner_model.typer.term2cat.duplicate_cats=GeneLocation_Species_Disease_Work_SportsSeason_Device_Media_SportCompetitionResult_EthnicGroup_Protocol_Award_Demographics_MeanOfTransportation_FileSystem_Medicine_Area_Flag_UnitOfWork_MedicalSpecialty_GrossDomesticProduct_Biomolecule_Identifier_Blazon_PersonFunction_List_TimePeriod_Event_Relationship_Altitude_TopicalConcept_Spreadsheet_Currency_Cipher_Browser_Tank_Food_Depth_Population_Statistic_StarCluster_Language_GrossDomesticProductPerCapita_ChemicalSubstance_ElectionDiagram_Diploma_Place_Algorithm_ChartsPlacements_Unknown_Activity_PublicService_Agent_Name_AnatomicalStructure_Colour \
	++ner_model.typer.term2cat.no_nc=True \
	++ner_model.typer.output_o_as_nc=True \
	++ner_model.typer.msc_args.o_sampling_ratio=1.0 \
	+output_dir=data/pseudo/8e1dde9d958882da575aad4ef12ad72bacde6032 \
        +gold_corpus=data/gold/6c65d7f80d7360db4020a9a2987bb195929256c3 
